{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Nicholas Schenone - A13599911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 trials\n",
    "- 7 classifiers\n",
    "    - SVM\n",
    "    - Logistic Regression\n",
    "    - Decision Tree\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "    - KNN\n",
    "    - Random Forest\n",
    "- 3 datasets\n",
    "    - Heart Disease: https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "    - Mushroom: https://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "    - Adult Data Set: https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "- 3 partitions (20/80, 50/50, 80/20)\n",
    "- 3 accuracies per (train, validation, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import json\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_pre_process(data_path=\"data/adult/adult.csv\", split=0.2):\n",
    "    df_adult = pd.read_csv(data_path)\n",
    "    df_adult_one_hot = pd.get_dummies(df_adult);\n",
    "    \n",
    "    X = df_adult_one_hot.iloc[:,0 : len(df_adult_one_hot.columns) - 1]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    y = df_adult_one_hot.iloc[:, len(df_adult_one_hot.columns) - 1]\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "def heart_pre_process(data_path=\"data/heart_disease/heart.csv\", split=0.2):\n",
    "    df_heart = pd.read_csv(data_path)\n",
    "    X = df_heart.iloc[:, 0 : len(df_heart.columns) - 1]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    y = df_heart.iloc[:, len(df_heart.columns) - 1]\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "def mushroom_pre_process(data_path=\"data/mushroom/mushroom.csv\", split=0.2):\n",
    "    df_mushroom = pd.read_csv(data_path, header=None)\n",
    "    df_mush_one_hot = pd.get_dummies(df_mushroom);\n",
    "    \n",
    "    X = df_mush_one_hot.iloc[:,1:]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    y = df_mush_one_hot.iloc[:, :1]\n",
    "    y = y.values.ravel()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "def pre_process(dataset, split=0.2):\n",
    "    if dataset == \"happy\":\n",
    "        return happiness_pre_process(split=split)\n",
    "    elif dataset == \"mush\":\n",
    "        return mushroom_pre_process(split=split)\n",
    "    elif dataset == \"heart\":\n",
    "        return heart_pre_process(split=split)\n",
    "    elif dataset == \"adult\":\n",
    "        return adult_pre_process(split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_X, heart_y, heart_X_train, heart_X_test, heart_y_train, heart_y_test = heart_pre_process(split=0.2)\n",
    "\n",
    "mush_X, mush_y, mush_X_train, mush_X_test, mush_y_train, mush_y_test = mushroom_pre_process(split=0.2)\n",
    "\n",
    "adult_X, adult_y, adult_X_train, adult_X_test, adult_y_train, adult_y_test = adult_pre_process(split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def clf_SVM(param_grid):\n",
    "    return svm.SVC(C = param_grid[\"C\"],\n",
    "                   gamma=param_grid[\"gamma\"],\n",
    "                   kernel=param_grid[\"kernel\"],\n",
    "                   max_iter = 10000)\n",
    "\n",
    "# Logistic Regression\n",
    "def clf_log(param_grid):\n",
    "    return LogisticRegression(C = param_grid[\"C\"],\n",
    "                              penalty = param_grid[\"penalty\"],\n",
    "                              solver=\"liblinear\",\n",
    "                              max_iter = 10000)\n",
    "\n",
    "# Decision Tree\n",
    "def clf_tree(param_grid):\n",
    "    return DecisionTreeClassifier(criterion=param_grid[\"criterion\"],\n",
    "                                  max_depth=param_grid[\"max_depth\"])\n",
    "\n",
    "# Perceptron\n",
    "def clf_perc(param_grid):\n",
    "    return Perceptron(penalty=param_grid[\"penalty\"],\n",
    "                      alpha=param_grid[\"alpha\"],\n",
    "                      max_iter=param_grid[\"max_iter\"],\n",
    "                      tol=param_grid[\"tol\"],\n",
    "                      early_stopping=param_grid[\"early_stopping\"])\n",
    "\n",
    "# Multi-Layer Perceptron\n",
    "def clf_mlp(param_grid):\n",
    "    return MLPClassifier(activation=param_grid[\"activation\"],\n",
    "                      solver=param_grid[\"solver\"],\n",
    "                      hidden_layer_sizes=param_grid[\"hidden_layer_sizes\"],\n",
    "                      max_iter=param_grid[\"max_iter\"],\n",
    "                      tol=param_grid[\"tol\"],\n",
    "                      early_stopping=param_grid[\"early_stopping\"])\n",
    "\n",
    "# KNN\n",
    "def clf_knn(param_grid):\n",
    "    return KNeighborsClassifier(n_neighbors=param_grid[\"n_neighbors\"])\n",
    "\n",
    "# Random Forest\n",
    "def clf_rf(param_grid):\n",
    "    return RandomForestClassifier(bootstrap=param_grid[\"bootstrap\"],\n",
    "                                 max_depth=param_grid[\"max_depth\"],\n",
    "                                 max_features=param_grid[\"max_features\"],\n",
    "                                 min_samples_leaf=param_grid[\"min_samples_leaf\"],\n",
    "                                 min_samples_split=param_grid[\"min_samples_split\"],\n",
    "                                 n_estimators=param_grid[\"n_estimators\"])\n",
    "\n",
    "# General\n",
    "def clf(model, param_grid):\n",
    "    if model == \"svm\":\n",
    "        return clf_SVM(param_grid)\n",
    "    elif model==\"log\":\n",
    "        return clf_log(param_grid)\n",
    "    elif model==\"tree\":\n",
    "        return clf_tree(param_grid)\n",
    "    elif model==\"perc\":\n",
    "        return clf_perc(param_grid)\n",
    "    elif model==\"mlp\":\n",
    "        return clf_mlp(param_grid)\n",
    "    elif model==\"knn\":\n",
    "        return clf_knn(param_grid)\n",
    "    elif model==\"rf\":\n",
    "        return clf_rf(param_grid)\n",
    "    \n",
    "def train_model(classifier, X_train, y_train):\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "def hyper_tune(X_train, y_train, estimator, param_grid, k_top=3):\n",
    "    grid_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, cv=10, n_iter=20, n_jobs=-1, verbose=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    results.sort_values(by='rank_test_score', inplace=True)\n",
    "    out = []\n",
    "    [out.append(results.loc[i, 'params']) for i in range(k_top)]\n",
    "    print(f\"Best {k_top} params:\", out)\n",
    "    return out\n",
    "\n",
    "def evalModel(classifer, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    f_score = f1_score(y_test, y_pred, average=\"macro\") \n",
    "    \n",
    "    return (accuracy, precision, recall, f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    \"C\" : [1, 10, 100, 1000, 10000],\n",
    "    \"gamma\" : [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    \"kernel\" : [\"linear\", \"rbf\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'kernel': 'rbf', 'gamma': 1e-06, 'C': 10}, {'kernel': 'linear', 'gamma': 1e-06, 'C': 10}, {'kernel': 'rbf', 'gamma': 0.01, 'C': 10000}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Mushroom SVM Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, svm.SVC(), svm_param_grid)\n",
    "\n",
    "with open('params/svm/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1900s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0326s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0971s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1945s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'kernel': 'rbf', 'gamma': 0.01, 'C': 10000}, {'kernel': 'rbf', 'gamma': 1e-05, 'C': 1000}, {'kernel': 'linear', 'gamma': 0.001, 'C': 1}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.7min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Heart SVM Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, svm.SVC(), svm_param_grid)\n",
    "\n",
    "with open('params/svm/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'kernel': 'rbf', 'gamma': 1e-06, 'C': 1000}, {'kernel': 'linear', 'gamma': 0.0001, 'C': 1}, {'kernel': 'rbf', 'gamma': 0.001, 'C': 100}]\n"
     ]
    }
   ],
   "source": [
    "# Adult SVM Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, svm.SVC(), svm_param_grid)\n",
    "\n",
    "with open('params/svm/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param_grid = {\n",
    "    \"C\" : [1, 10, 100, 1000, 10000],\n",
    "    \"penalty\" : [\"l1\", \"l2\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    8.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'penalty': 'l1', 'C': 1}, {'penalty': 'l2', 'C': 1}, {'penalty': 'l1', 'C': 10}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.2s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Logistic Regression Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, LogisticRegression(), log_param_grid)\n",
    "\n",
    "with open('params/log/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1925s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0855s.) Setting batch_size=4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'penalty': 'l1', 'C': 1}, {'penalty': 'l2', 'C': 1}, {'penalty': 'l1', 'C': 10}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0561s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Heart Logistic Regression Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, LogisticRegression(), log_param_grid)\n",
    "\n",
    "with open('params/log/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   43.0s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'penalty': 'l1', 'C': 1}, {'penalty': 'l2', 'C': 1}, {'penalty': 'l1', 'C': 10}]\n"
     ]
    }
   ],
   "source": [
    "# Adult Logistic Regression Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, LogisticRegression(), log_param_grid)\n",
    "\n",
    "with open('params/log/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param_grid = {\n",
    "    \"criterion\" : ['gini', 'entropy'],\n",
    "    \"max_depth\" : [4,6,8,12],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1993s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'max_depth': 4, 'criterion': 'gini'}, {'max_depth': 6, 'criterion': 'gini'}, {'max_depth': 8, 'criterion': 'gini'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Decision Tree Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, DecisionTreeClassifier(), tree_param_grid)\n",
    "\n",
    "with open('params/tree/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1751s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0386s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'max_depth': 4, 'criterion': 'gini'}, {'max_depth': 6, 'criterion': 'gini'}, {'max_depth': 8, 'criterion': 'gini'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0480s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    1.7s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Heart Decision Tree Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, DecisionTreeClassifier(), tree_param_grid)\n",
    "\n",
    "with open('params/tree/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    6.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'max_depth': 4, 'criterion': 'gini'}, {'max_depth': 6, 'criterion': 'gini'}, {'max_depth': 8, 'criterion': 'gini'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    8.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Adult Decision Tree Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, DecisionTreeClassifier(), tree_param_grid)\n",
    "\n",
    "with open('params/tree/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_param_grid = {\n",
    "    \"penalty\" : [None, \"l1\", \"l2\", \"elasticnet\"],\n",
    "    \"alpha\" : [0.001, 0.0001, 0.00001],\n",
    "    \"max_iter\" : [500, 1000, 2000],\n",
    "    \"tol\" : [1e-4, 1e-3, 1e-2],\n",
    "    \"early_stopping\" : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1983s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1249s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:    3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 0.0001, 'penalty': 'l1', 'max_iter': 1000, 'early_stopping': False, 'alpha': 1e-05}, {'tol': 0.0001, 'penalty': None, 'max_iter': 1000, 'early_stopping': True, 'alpha': 1e-05}, {'tol': 0.001, 'penalty': 'l1', 'max_iter': 500, 'early_stopping': True, 'alpha': 1e-05}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Perceptron Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, Perceptron(), perc_param_grid)\n",
    "\n",
    "with open('params/perc/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1984s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0357s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0867s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0442s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 0.01, 'penalty': 'l1', 'max_iter': 1000, 'early_stopping': True, 'alpha': 0.001}, {'tol': 0.01, 'penalty': 'elasticnet', 'max_iter': 2000, 'early_stopping': False, 'alpha': 1e-05}, {'tol': 0.001, 'penalty': None, 'max_iter': 2000, 'early_stopping': True, 'alpha': 0.0001}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.9s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Heart Perceptron Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, Perceptron(), perc_param_grid)\n",
    "\n",
    "with open('params/perc/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   21.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 0.001, 'penalty': 'l2', 'max_iter': 500, 'early_stopping': True, 'alpha': 1e-05}, {'tol': 0.001, 'penalty': 'l1', 'max_iter': 500, 'early_stopping': False, 'alpha': 1e-05}, {'tol': 0.0001, 'penalty': None, 'max_iter': 500, 'early_stopping': True, 'alpha': 0.0001}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   21.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Adult Perceptron Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, Perceptron(), perc_param_grid)\n",
    "\n",
    "with open('params/perc/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_param_grid = {\n",
    "    \"hidden_layer_sizes\" : [(100,), (50,), (200,), (25,)],\n",
    "    \"activation\" : [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"max_iter\" : [200, 100, 300],\n",
    "    \"tol\" : [1e-4, 1e-3, 1e-5],\n",
    "    \"early_stopping\" : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 1e-05, 'solver': 'lbfgs', 'max_iter': 300, 'hidden_layer_sizes': (200,), 'early_stopping': False, 'activation': 'identity'}, {'tol': 0.001, 'solver': 'adam', 'max_iter': 200, 'hidden_layer_sizes': (50,), 'early_stopping': False, 'activation': 'logistic'}, {'tol': 0.0001, 'solver': 'sgd', 'max_iter': 200, 'hidden_layer_sizes': (50,), 'early_stopping': False, 'activation': 'logistic'}]\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Perceptron Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, MLPClassifier(), mlp_param_grid)\n",
    "\n",
    "with open('params/mlp/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1781s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 193 out of 200 | elapsed:    9.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   10.1s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 1e-05, 'solver': 'adam', 'max_iter': 200, 'hidden_layer_sizes': (25,), 'early_stopping': False, 'activation': 'logistic'}, {'tol': 1e-05, 'solver': 'sgd', 'max_iter': 200, 'hidden_layer_sizes': (50,), 'early_stopping': False, 'activation': 'tanh'}, {'tol': 0.0001, 'solver': 'adam', 'max_iter': 200, 'hidden_layer_sizes': (50,), 'early_stopping': False, 'activation': 'tanh'}]\n"
     ]
    }
   ],
   "source": [
    "# Heart Perceptron Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, MLPClassifier(), mlp_param_grid)\n",
    "\n",
    "with open('params/mlp/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'tol': 1e-05, 'solver': 'sgd', 'max_iter': 200, 'hidden_layer_sizes': (50,), 'early_stopping': False, 'activation': 'tanh'}, {'tol': 0.0001, 'solver': 'sgd', 'max_iter': 100, 'hidden_layer_sizes': (200,), 'early_stopping': True, 'activation': 'identity'}, {'tol': 0.001, 'solver': 'adam', 'max_iter': 300, 'hidden_layer_sizes': (200,), 'early_stopping': True, 'activation': 'identity'}]\n"
     ]
    }
   ],
   "source": [
    "# Adult Perceptron Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, MLPClassifier(), mlp_param_grid)\n",
    "\n",
    "with open('params/mlp/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    \"n_neighbors\" : [1, 3, 5, 9, 15, 25, 50, 75, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   28.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   31.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Decision Tree Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, KNeighborsClassifier(), knn_param_grid)\n",
    "\n",
    "with open('params/knn/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1963s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0193s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0828s.) Setting batch_size=8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    1.4s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Heart Decision Tree Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, KNeighborsClassifier(), knn_param_grid)\n",
    "\n",
    "with open('params/knn/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}]\n"
     ]
    }
   ],
   "source": [
    "# Adult Decision Tree Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, KNeighborsClassifier(), knn_param_grid)\n",
    "\n",
    "with open('params/knn/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}, {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}, {'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}]\n"
     ]
    }
   ],
   "source": [
    "# Mushroom Decision Tree Tuning\n",
    "best_param_grid_mush = hyper_tune(mush_X_train, mush_y_train, RandomForestClassifier(), rf_param_grid)\n",
    "\n",
    "with open('params/rf/best_param_grid_mush', 'w') as f:\n",
    "    json.dump(best_param_grid_mush, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.6min finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}, {'n_estimators': 1400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}, {'n_estimators': 1400, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': False}]\n"
     ]
    }
   ],
   "source": [
    "# Heart Decision Tree Tuning\n",
    "best_param_grid_heart = hyper_tune(heart_X_train, heart_y_train, RandomForestClassifier(), rf_param_grid)\n",
    "\n",
    "with open('params/rf/best_param_grid_heart', 'w') as f:\n",
    "    json.dump(best_param_grid_heart, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 47.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3 params: [{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': True}, {'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': True}, {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}]\n"
     ]
    }
   ],
   "source": [
    "# Adult Decision Tree Tuning\n",
    "best_param_grid_adult = hyper_tune(adult_X_train, adult_y_train, RandomForestClassifier(), rf_param_grid)\n",
    "\n",
    "with open('params/rf/best_param_grid_adult', 'w') as f:\n",
    "    json.dump(best_param_grid_adult, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with best Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/svm/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/svm/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/svm/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom SVM\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_SVM(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart SVM\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_SVM(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult SVM\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_SVM(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/log/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/log/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/log/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom Logistic Regression Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_log(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Logistic Regression Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_log(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult Logistic Regression Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_log(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/tree/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/tree/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/tree/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom Decision Tree Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_tree(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Decision Tree Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_tree(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult Decision Tree Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_tree(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/perc/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/perc/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/perc/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom Decision Tree Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_perc(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart Decision Tree Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_perc(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult Perceptron Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_perc(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/mlp/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/mlp/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/mlp/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom MLP Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_mlp(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart MLP Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_mlp(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult MLP Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_mlp(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/knn/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/knn/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/knn/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom KNN Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_knn(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart KNN Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_knn(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult KNN Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_knn(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params/rf/best_param_grid_mush', 'r') as f:\n",
    "    best_param_grid_mush = json.load(f)\n",
    "    \n",
    "with open('params/rf/best_param_grid_heart', 'r') as f:\n",
    "    best_param_grid_heart = json.load(f)\n",
    "    \n",
    "with open('params/rf/best_param_grid_adult', 'r') as f:\n",
    "    best_param_grid_adult = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mushroom RF Training/Eval\n",
    "for i in range(len(best_param_grid_mush)):\n",
    "    print(\"Best params:\", best_param_grid_mush[i], \"\\n\")\n",
    "    classifier = clf_rf(best_param_grid_mush[i])\n",
    "    train_model(classifier, mush_X_train, mush_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, mush_X_test, mush_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heart RF Training/Eval\n",
    "for i in range(len(best_param_grid_heart)):\n",
    "    print(\"Best params:\", best_param_grid_heart[i], \"\\n\")\n",
    "    classifier = clf_rf(best_param_grid_heart[i])\n",
    "    train_model(classifier, heart_X_train, heart_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, heart_X_test, heart_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult RF Training/Eval\n",
    "for i in range(len(best_param_grid_adult)):\n",
    "    print(\"Best params:\", best_param_grid_adult[i], \"\\n\")\n",
    "    classifier = clf_rf(best_param_grid_adult[i])\n",
    "    train_model(classifier, adult_X_train, adult_y_train)\n",
    "    acc, prec, rec, f = evalModel(classifier, adult_X_test, adult_y_test)\n",
    "    print(f\"Accuracy: {acc} \\nPrecision: {prec} \\nRecall: {rec} \\nF1 Score {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 trials\n",
    "    - 3 datasets\n",
    "        - 4 models\n",
    "            - 3 splits (80/20, 20/80, 50/50)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 3\n",
    "datasets = ['adult', 'mush', 'heart']\n",
    "splits = [0.2, 0.8]\n",
    "models = ['log', 'svm', 'tree', 'perc', 'mlp', 'knn', 'rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For i in three different datasets\n",
    "   For j in three different partitions (20/80,50/50,80/20):\n",
    "        For t in three different trials\n",
    "            For c in three different classifiers\n",
    "                 cross validate\n",
    "                 find the optimal hyper-parameter\n",
    "                 train using the hyper-parameter above\n",
    "                 obtain the training and validation accuracy/error\n",
    "                 test\n",
    "                 obtain the testing accuracy\n",
    "       compute the averaged accuracy (training, validation, and testing) for each classifier c out of three trials\n",
    "       rank order the classifiers\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training adult-0.2-0-log\n",
      "Evaluating adult-0.2-0-log\n",
      "Training adult-0.2-0-svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating adult-0.2-0-svm\n",
      "Training adult-0.2-0-tree\n",
      "Evaluating adult-0.2-0-tree\n",
      "Training adult-0.2-0-perc\n",
      "Evaluating adult-0.2-0-perc\n",
      "Training adult-0.2-0-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating adult-0.2-0-mlp\n",
      "Training adult-0.2-0-knn\n",
      "Evaluating adult-0.2-0-knn\n",
      "Training adult-0.2-0-rf\n",
      "Evaluating adult-0.2-0-rf\n",
      "Training adult-0.2-1-log\n",
      "Evaluating adult-0.2-1-log\n",
      "Training adult-0.2-1-svm\n",
      "Evaluating adult-0.2-1-svm\n",
      "Training adult-0.2-1-tree\n",
      "Evaluating adult-0.2-1-tree\n",
      "Training adult-0.2-1-perc\n",
      "Evaluating adult-0.2-1-perc\n",
      "Training adult-0.2-1-mlp\n",
      "Evaluating adult-0.2-1-mlp\n",
      "Training adult-0.2-1-knn\n",
      "Evaluating adult-0.2-1-knn\n",
      "Training adult-0.2-1-rf\n",
      "Evaluating adult-0.2-1-rf\n",
      "Training adult-0.2-2-log\n",
      "Evaluating adult-0.2-2-log\n",
      "Training adult-0.2-2-svm\n",
      "Evaluating adult-0.2-2-svm\n",
      "Training adult-0.2-2-tree\n",
      "Evaluating adult-0.2-2-tree\n",
      "Training adult-0.2-2-perc\n",
      "Evaluating adult-0.2-2-perc\n",
      "Training adult-0.2-2-mlp\n",
      "Evaluating adult-0.2-2-mlp\n",
      "Training adult-0.2-2-knn\n",
      "Evaluating adult-0.2-2-knn\n",
      "Training adult-0.2-2-rf\n",
      "Evaluating adult-0.2-2-rf\n",
      "Training adult-0.8-0-log\n",
      "Evaluating adult-0.8-0-log\n",
      "Training adult-0.8-0-svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating adult-0.8-0-svm\n",
      "Training adult-0.8-0-tree\n",
      "Evaluating adult-0.8-0-tree\n",
      "Training adult-0.8-0-perc\n",
      "Evaluating adult-0.8-0-perc\n",
      "Training adult-0.8-0-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating adult-0.8-0-mlp\n",
      "Training adult-0.8-0-knn\n",
      "Evaluating adult-0.8-0-knn\n",
      "Training adult-0.8-0-rf\n",
      "Evaluating adult-0.8-0-rf\n",
      "Training adult-0.8-1-log\n",
      "Evaluating adult-0.8-1-log\n",
      "Training adult-0.8-1-svm\n",
      "Evaluating adult-0.8-1-svm\n",
      "Training adult-0.8-1-tree\n",
      "Evaluating adult-0.8-1-tree\n",
      "Training adult-0.8-1-perc\n",
      "Evaluating adult-0.8-1-perc\n",
      "Training adult-0.8-1-mlp\n",
      "Evaluating adult-0.8-1-mlp\n",
      "Training adult-0.8-1-knn\n",
      "Evaluating adult-0.8-1-knn\n",
      "Training adult-0.8-1-rf\n",
      "Evaluating adult-0.8-1-rf\n",
      "Training adult-0.8-2-log\n",
      "Evaluating adult-0.8-2-log\n",
      "Training adult-0.8-2-svm\n",
      "Evaluating adult-0.8-2-svm\n",
      "Training adult-0.8-2-tree\n",
      "Evaluating adult-0.8-2-tree\n",
      "Training adult-0.8-2-perc\n",
      "Evaluating adult-0.8-2-perc\n",
      "Training adult-0.8-2-mlp\n",
      "Evaluating adult-0.8-2-mlp\n",
      "Training adult-0.8-2-knn\n",
      "Evaluating adult-0.8-2-knn\n",
      "Training adult-0.8-2-rf\n",
      "Evaluating adult-0.8-2-rf\n",
      "Training mush-0.2-0-log\n",
      "Evaluating mush-0.2-0-log\n",
      "Training mush-0.2-0-svm\n",
      "Evaluating mush-0.2-0-svm\n",
      "Training mush-0.2-0-tree\n",
      "Evaluating mush-0.2-0-tree\n",
      "Training mush-0.2-0-perc\n",
      "Evaluating mush-0.2-0-perc\n",
      "Training mush-0.2-0-mlp\n",
      "Evaluating mush-0.2-0-mlp\n",
      "Training mush-0.2-0-knn\n",
      "Evaluating mush-0.2-0-knn\n",
      "Training mush-0.2-0-rf\n",
      "Evaluating mush-0.2-0-rf\n",
      "Training mush-0.2-1-log\n",
      "Evaluating mush-0.2-1-log\n",
      "Training mush-0.2-1-svm\n",
      "Evaluating mush-0.2-1-svm\n",
      "Training mush-0.2-1-tree\n",
      "Evaluating mush-0.2-1-tree\n",
      "Training mush-0.2-1-perc\n",
      "Evaluating mush-0.2-1-perc\n",
      "Training mush-0.2-1-mlp\n",
      "Evaluating mush-0.2-1-mlp\n",
      "Training mush-0.2-1-knn\n",
      "Evaluating mush-0.2-1-knn\n",
      "Training mush-0.2-1-rf\n",
      "Evaluating mush-0.2-1-rf\n",
      "Training mush-0.2-2-log\n",
      "Evaluating mush-0.2-2-log\n",
      "Training mush-0.2-2-svm\n",
      "Evaluating mush-0.2-2-svm\n",
      "Training mush-0.2-2-tree\n",
      "Evaluating mush-0.2-2-tree\n",
      "Training mush-0.2-2-perc\n",
      "Evaluating mush-0.2-2-perc\n",
      "Training mush-0.2-2-mlp\n",
      "Evaluating mush-0.2-2-mlp\n",
      "Training mush-0.2-2-knn\n",
      "Evaluating mush-0.2-2-knn\n",
      "Training mush-0.2-2-rf\n",
      "Evaluating mush-0.2-2-rf\n",
      "Training mush-0.8-0-log\n",
      "Evaluating mush-0.8-0-log\n",
      "Training mush-0.8-0-svm\n",
      "Evaluating mush-0.8-0-svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mush-0.8-0-tree\n",
      "Evaluating mush-0.8-0-tree\n",
      "Training mush-0.8-0-perc\n",
      "Evaluating mush-0.8-0-perc\n",
      "Training mush-0.8-0-mlp\n",
      "Evaluating mush-0.8-0-mlp\n",
      "Training mush-0.8-0-knn\n",
      "Evaluating mush-0.8-0-knn\n",
      "Training mush-0.8-0-rf\n",
      "Evaluating mush-0.8-0-rf\n",
      "Training mush-0.8-1-log\n",
      "Evaluating mush-0.8-1-log\n",
      "Training mush-0.8-1-svm\n",
      "Evaluating mush-0.8-1-svm\n",
      "Training mush-0.8-1-tree\n",
      "Evaluating mush-0.8-1-tree\n",
      "Training mush-0.8-1-perc\n",
      "Evaluating mush-0.8-1-perc\n",
      "Training mush-0.8-1-mlp\n",
      "Evaluating mush-0.8-1-mlp\n",
      "Training mush-0.8-1-knn\n",
      "Evaluating mush-0.8-1-knn\n",
      "Training mush-0.8-1-rf\n",
      "Evaluating mush-0.8-1-rf\n",
      "Training mush-0.8-2-log\n",
      "Evaluating mush-0.8-2-log\n",
      "Training mush-0.8-2-svm\n",
      "Evaluating mush-0.8-2-svm\n",
      "Training mush-0.8-2-tree\n",
      "Evaluating mush-0.8-2-tree\n",
      "Training mush-0.8-2-perc\n",
      "Evaluating mush-0.8-2-perc\n",
      "Training mush-0.8-2-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating mush-0.8-2-mlp\n",
      "Training mush-0.8-2-knn\n",
      "Evaluating mush-0.8-2-knn\n",
      "Training mush-0.8-2-rf\n",
      "Evaluating mush-0.8-2-rf\n",
      "Training heart-0.2-0-log\n",
      "Evaluating heart-0.2-0-log\n",
      "Training heart-0.2-0-svm\n",
      "Evaluating heart-0.2-0-svm\n",
      "Training heart-0.2-0-tree\n",
      "Evaluating heart-0.2-0-tree\n",
      "Training heart-0.2-0-perc\n",
      "Evaluating heart-0.2-0-perc\n",
      "Training heart-0.2-0-mlp\n",
      "Evaluating heart-0.2-0-mlp\n",
      "Training heart-0.2-0-knn\n",
      "Evaluating heart-0.2-0-knn\n",
      "Training heart-0.2-0-rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:241: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.2-0-rf\n",
      "Training heart-0.2-1-log\n",
      "Evaluating heart-0.2-1-log\n",
      "Training heart-0.2-1-svm\n",
      "Evaluating heart-0.2-1-svm\n",
      "Training heart-0.2-1-tree\n",
      "Evaluating heart-0.2-1-tree\n",
      "Training heart-0.2-1-perc\n",
      "Evaluating heart-0.2-1-perc\n",
      "Training heart-0.2-1-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.2-1-mlp\n",
      "Training heart-0.2-1-knn\n",
      "Evaluating heart-0.2-1-knn\n",
      "Training heart-0.2-1-rf\n",
      "Evaluating heart-0.2-1-rf\n",
      "Training heart-0.2-2-log\n",
      "Evaluating heart-0.2-2-log\n",
      "Training heart-0.2-2-svm\n",
      "Evaluating heart-0.2-2-svm\n",
      "Training heart-0.2-2-tree\n",
      "Evaluating heart-0.2-2-tree\n",
      "Training heart-0.2-2-perc\n",
      "Evaluating heart-0.2-2-perc\n",
      "Training heart-0.2-2-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.2-2-mlp\n",
      "Training heart-0.2-2-knn\n",
      "Evaluating heart-0.2-2-knn\n",
      "Training heart-0.2-2-rf\n",
      "Evaluating heart-0.2-2-rf\n",
      "Training heart-0.8-0-log\n",
      "Evaluating heart-0.8-0-log\n",
      "Training heart-0.8-0-svm\n",
      "Evaluating heart-0.8-0-svm\n",
      "Training heart-0.8-0-tree\n",
      "Evaluating heart-0.8-0-tree\n",
      "Training heart-0.8-0-perc\n",
      "Evaluating heart-0.8-0-perc\n",
      "Training heart-0.8-0-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.8-0-mlp\n",
      "Training heart-0.8-0-knn\n",
      "Evaluating heart-0.8-0-knn\n",
      "Training heart-0.8-0-rf\n",
      "Evaluating heart-0.8-0-rf\n",
      "Training heart-0.8-1-log\n",
      "Evaluating heart-0.8-1-log\n",
      "Training heart-0.8-1-svm\n",
      "Evaluating heart-0.8-1-svm\n",
      "Training heart-0.8-1-tree\n",
      "Evaluating heart-0.8-1-tree\n",
      "Training heart-0.8-1-perc\n",
      "Evaluating heart-0.8-1-perc\n",
      "Training heart-0.8-1-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.8-1-mlp\n",
      "Training heart-0.8-1-knn\n",
      "Evaluating heart-0.8-1-knn\n",
      "Training heart-0.8-1-rf\n",
      "Evaluating heart-0.8-1-rf\n",
      "Training heart-0.8-2-log\n",
      "Evaluating heart-0.8-2-log\n",
      "Training heart-0.8-2-svm\n",
      "Evaluating heart-0.8-2-svm\n",
      "Training heart-0.8-2-tree\n",
      "Evaluating heart-0.8-2-tree\n",
      "Training heart-0.8-2-perc\n",
      "Evaluating heart-0.8-2-perc\n",
      "Training heart-0.8-2-mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating heart-0.8-2-mlp\n",
      "Training heart-0.8-2-knn\n",
      "Evaluating heart-0.8-2-knn\n",
      "Training heart-0.8-2-rf\n",
      "Evaluating heart-0.8-2-rf\n"
     ]
    }
   ],
   "source": [
    "# Loop through datasets\n",
    "dataset_scores = {}\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # Loop through dataset splits\n",
    "    split_scores = {}\n",
    "    for split in splits:\n",
    "\n",
    "        # Prepare data splits\n",
    "        X, y, X_train, X_test, y_train, y_test = pre_process(dataset=dataset, split=split)\n",
    "        \n",
    "        # Loop through trials\n",
    "        trial_scores = {}\n",
    "        for i in range(num_trials):\n",
    "            \n",
    "            # Loop through models\n",
    "            model_scores = {}\n",
    "            for model in models:\n",
    "                \n",
    "                # Load best model params for given model and dataset\n",
    "                with open(f'params/{model}/best_param_grid_{dataset}', 'r') as f:\n",
    "                    best_param_grid = json.load(f)\n",
    "    \n",
    "                    # Create classifier\n",
    "                    classifier = clf(model=model, param_grid=best_param_grid[i])\n",
    "\n",
    "                    # Train classifier\n",
    "                    print(f\"Training {dataset}-{split}-{i}-{model}\")\n",
    "                    train_model(classifier, X_train, y_train)\n",
    "\n",
    "                    # Evaluate classifier\n",
    "                    print(f\"Evaluating {dataset}-{split}-{i}-{model}\")\n",
    "                    acc, prec, rec, f = evalModel(classifier, X_test, y_test)\n",
    "                    classifier_eval = {\"accuracy\" : acc, \"precision\": prec, \"recall\" : rec, \"f1_score\" : f}              \n",
    "                    \n",
    "                # Add evaluation scores for given model\n",
    "                model_scores.update({f\"model_{model}\" : classifier_eval})\n",
    "                \n",
    "            # Add model scores for given trial\n",
    "            trial_scores.update({f\"trial_{i}\" : model_scores})\n",
    "\n",
    "        # Add trial scores for given model\n",
    "        split_scores.update({f\"split_{split}\": trial_scores})\n",
    "\n",
    "    # Add split scores for given dataset\n",
    "    dataset_scores.update({f\"data_{dataset}\": split_scores})\n",
    "    \n",
    "with open('scores/dataset_scores', 'w') as f:\n",
    "    json.dump(dataset_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scores/dataset_scores', 'r') as f:\n",
    "    dataset_scores = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_adult': {'split_0.2': {'trial_0': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 0.9986692599037773,\n",
       "     'precision': 0.9992717902755994,\n",
       "     'recall': 0.9924065420560748,\n",
       "     'f1_score': 0.9958098499293646},\n",
       "    'model_mlp': {'accuracy': 0.999181083017709,\n",
       "     'precision': 0.999551619773568,\n",
       "     'recall': 0.9953271028037383,\n",
       "     'f1_score': 0.9974282914789022},\n",
       "    'model_knn': {'accuracy': 0.954550107482854,\n",
       "     'precision': 0.8609517384899257,\n",
       "     'recall': 0.8510091974234841,\n",
       "     'f1_score': 0.8558918206877745},\n",
       "    'model_rf': {'accuracy': 0.9353055583990173,\n",
       "     'precision': 0.9668936616029336,\n",
       "     'recall': 0.6308411214953271,\n",
       "     'f1_score': 0.690287459417376}},\n",
       "   'trial_1': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 0.9995905415088545,\n",
       "     'precision': 0.9997757093192778,\n",
       "     'recall': 0.9976635514018692,\n",
       "     'f1_score': 0.9987168693134876},\n",
       "    'model_knn': {'accuracy': 0.9586446923943085,\n",
       "     'precision': 0.9015480348383287,\n",
       "     'recall': 0.8226282805436981,\n",
       "     'f1_score': 0.8567566194254985},\n",
       "    'model_rf': {'accuracy': 0.9940628518783908,\n",
       "     'precision': 0.9967673614981607,\n",
       "     'recall': 0.9661214953271028,\n",
       "     'f1_score': 0.9808451861073255}},\n",
       "   'trial_2': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.9993858122632818,\n",
       "     'precision': 0.9991327821890034,\n",
       "     'recall': 0.9970233414177129,\n",
       "     'f1_score': 0.9980753039702315},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 0.9985668952809909,\n",
       "     'precision': 0.995518530110906,\n",
       "     'recall': 0.995518530110906,\n",
       "     'f1_score': 0.995518530110906},\n",
       "    'model_mlp': {'accuracy': 0.9993858122632818,\n",
       "     'precision': 0.9965197215777262,\n",
       "     'recall': 0.9996634129922586,\n",
       "     'f1_score': 0.9980854333008},\n",
       "    'model_knn': {'accuracy': 0.9578257754120176,\n",
       "     'precision': 0.9190843957720388,\n",
       "     'recall': 0.7984188536957988,\n",
       "     'f1_score': 0.8463472997199394},\n",
       "    'model_rf': {'accuracy': 0.9965196028252636,\n",
       "     'precision': 0.9980999217614843,\n",
       "     'recall': 0.9801401869158879,\n",
       "     'f1_score': 0.9889170438331774}}},\n",
       "  'split_0.8': {'trial_0': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 0.9973895685110303,\n",
       "     'precision': 0.9982796017118533,\n",
       "     'recall': 0.983759503738789,\n",
       "     'f1_score': 0.9908904562616199},\n",
       "    'model_mlp': {'accuracy': 0.9981317500127962,\n",
       "     'precision': 0.9988357440175883,\n",
       "     'recall': 0.9883129555010417,\n",
       "     'f1_score': 0.9935068636243611},\n",
       "    'model_knn': {'accuracy': 0.9383477504222757,\n",
       "     'precision': 0.7871305921910979,\n",
       "     'recall': 0.7938393410909286,\n",
       "     'f1_score': 0.7904352490330252},\n",
       "    'model_rf': {'accuracy': 0.9370937196089472,\n",
       "     'precision': 0.9680347482313774,\n",
       "     'recall': 0.601491569390402,\n",
       "     'f1_score': 0.6522227691577693}},\n",
       "   'trial_1': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 0.9991554486359215,\n",
       "     'precision': 0.9995419593037782,\n",
       "     'recall': 0.9946498054474708,\n",
       "     'f1_score': 0.9970813881506113},\n",
       "    'model_mlp': {'accuracy': 0.999053078773609,\n",
       "     'precision': 0.9993363587884129,\n",
       "     'recall': 0.9941495313765281,\n",
       "     'f1_score': 0.9967266407881785},\n",
       "    'model_knn': {'accuracy': 0.9418795106720581,\n",
       "     'precision': 0.821392029218269,\n",
       "     'recall': 0.7337945779721922,\n",
       "     'f1_score': 0.7690762149908317},\n",
       "    'model_rf': {'accuracy': 0.9871269898141987,\n",
       "     'precision': 0.9931082673389418,\n",
       "     'recall': 0.9184500648508431,\n",
       "     'f1_score': 0.9521348104645506}},\n",
       "   'trial_2': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.9989251164457184,\n",
       "     'precision': 0.9986672899690759,\n",
       "     'recall': 0.9939318332769335,\n",
       "     'f1_score': 0.9962859569037494},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 0.9938066233300916,\n",
       "     'precision': 0.9711531767436026,\n",
       "     'recall': 0.9872991903284851,\n",
       "     'f1_score': 0.979061012622116},\n",
       "    'model_mlp': {'accuracy': 0.9984900445308901,\n",
       "     'precision': 0.9931517661171169,\n",
       "     'recall': 0.9965121093948492,\n",
       "     'f1_score': 0.9948250515116883},\n",
       "    'model_knn': {'accuracy': 0.9427240620361366,\n",
       "     'precision': 0.8468056686239633,\n",
       "     'recall': 0.7043096980030121,\n",
       "     'f1_score': 0.7533468906271493},\n",
       "    'model_rf': {'accuracy': 0.988713722680043,\n",
       "     'precision': 0.993947462326041,\n",
       "     'recall': 0.9285019455252919,\n",
       "     'f1_score': 0.9584534695992032}}}},\n",
       " 'data_mush': {'split_0.2': {'trial_0': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.9046153846153846,\n",
       "     'precision': 0.9211597151576806,\n",
       "     'recall': 0.9027603513174405,\n",
       "     'f1_score': 0.9033491185247746},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_knn': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}},\n",
       "   'trial_1': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_knn': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}},\n",
       "   'trial_2': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.9993846153846154,\n",
       "     'precision': 0.9993968636911943,\n",
       "     'recall': 0.9993726474278545,\n",
       "     'f1_score': 0.9993843766538958},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 0.9993846153846154,\n",
       "     'precision': 0.9993968636911943,\n",
       "     'recall': 0.9993726474278545,\n",
       "     'f1_score': 0.9993843766538958},\n",
       "    'model_knn': {'accuracy': 0.9993846153846154,\n",
       "     'precision': 0.9993968636911943,\n",
       "     'recall': 0.9993726474278545,\n",
       "     'f1_score': 0.9993843766538958},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}}},\n",
       "  'split_0.8': {'trial_0': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.5178461538461538,\n",
       "     'precision': 0.2589230769230769,\n",
       "     'recall': 0.5,\n",
       "     'f1_score': 0.34117170079059395},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 0.9995384615384615,\n",
       "     'precision': 0.9995547640249332,\n",
       "     'recall': 0.9995213784301212,\n",
       "     'f1_score': 0.9995378574716893},\n",
       "    'model_knn': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}},\n",
       "   'trial_1': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 0.9987692307692307,\n",
       "     'precision': 0.9987903034669751,\n",
       "     'recall': 0.9987456683278599,\n",
       "     'f1_score': 0.9987676061678846},\n",
       "    'model_knn': {'accuracy': 0.9983076923076923,\n",
       "     'precision': 0.9983223425034027,\n",
       "     'recall': 0.9982890392721844,\n",
       "     'f1_score': 0.9983054773961941},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}},\n",
       "   'trial_2': {'model_log': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_svm': {'accuracy': 0.9989230769230769,\n",
       "     'precision': 0.9989623480581085,\n",
       "     'recall': 0.9988832163369497,\n",
       "     'f1_score': 0.9989216189774582},\n",
       "    'model_tree': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_perc': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0},\n",
       "    'model_mlp': {'accuracy': 0.9989230769230769,\n",
       "     'precision': 0.9989623480581085,\n",
       "     'recall': 0.9988832163369497,\n",
       "     'f1_score': 0.9989216189774582},\n",
       "    'model_knn': {'accuracy': 0.9976923076923077,\n",
       "     'precision': 0.9976839640638812,\n",
       "     'recall': 0.997694862207419,\n",
       "     'f1_score': 0.9976893894321773},\n",
       "    'model_rf': {'accuracy': 1.0,\n",
       "     'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1_score': 1.0}}}},\n",
       " 'data_heart': {'split_0.2': {'trial_0': {'model_log': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_svm': {'accuracy': 0.7377049180327869,\n",
       "     'precision': 0.741111111111111,\n",
       "     'recall': 0.7338362068965517,\n",
       "     'f1_score': 0.7342047930283224},\n",
       "    'model_tree': {'accuracy': 0.8032786885245902,\n",
       "     'precision': 0.8163615560640732,\n",
       "     'recall': 0.7979525862068966,\n",
       "     'f1_score': 0.798901098901099},\n",
       "    'model_perc': {'accuracy': 0.7540983606557377,\n",
       "     'precision': 0.7786585365853658,\n",
       "     'recall': 0.7462284482758621,\n",
       "     'f1_score': 0.7441990494828068},\n",
       "    'model_mlp': {'accuracy': 0.8032786885245902,\n",
       "     'precision': 0.8088888888888889,\n",
       "     'recall': 0.7995689655172413,\n",
       "     'f1_score': 0.8006535947712419},\n",
       "    'model_knn': {'accuracy': 0.7704918032786885,\n",
       "     'precision': 0.775,\n",
       "     'recall': 0.7667025862068966,\n",
       "     'f1_score': 0.7674291938997821},\n",
       "    'model_rf': {'accuracy': 0.8360655737704918,\n",
       "     'precision': 0.8376906318082789,\n",
       "     'recall': 0.834051724137931,\n",
       "     'f1_score': 0.83495670995671}},\n",
       "   'trial_1': {'model_log': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_svm': {'accuracy': 0.8032786885245902,\n",
       "     'precision': 0.8088888888888889,\n",
       "     'recall': 0.7995689655172413,\n",
       "     'f1_score': 0.8006535947712419},\n",
       "    'model_tree': {'accuracy': 0.8360655737704918,\n",
       "     'precision': 0.8427777777777778,\n",
       "     'recall': 0.8324353448275862,\n",
       "     'f1_score': 0.8338779956427015},\n",
       "    'model_perc': {'accuracy': 0.7540983606557377,\n",
       "     'precision': 0.79328165374677,\n",
       "     'recall': 0.7446120689655172,\n",
       "     'f1_score': 0.7404255319148937},\n",
       "    'model_mlp': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_knn': {'accuracy': 0.7704918032786885,\n",
       "     'precision': 0.7814645308924485,\n",
       "     'recall': 0.7650862068965517,\n",
       "     'f1_score': 0.7653846153846153},\n",
       "    'model_rf': {'accuracy': 0.8360655737704918,\n",
       "     'precision': 0.8376906318082789,\n",
       "     'recall': 0.834051724137931,\n",
       "     'f1_score': 0.83495670995671}},\n",
       "   'trial_2': {'model_log': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_svm': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_tree': {'accuracy': 0.8032786885245902,\n",
       "     'precision': 0.8088888888888889,\n",
       "     'recall': 0.7995689655172413,\n",
       "     'f1_score': 0.8006535947712419},\n",
       "    'model_perc': {'accuracy': 0.8360655737704918,\n",
       "     'precision': 0.8376906318082789,\n",
       "     'recall': 0.834051724137931,\n",
       "     'f1_score': 0.83495670995671},\n",
       "    'model_mlp': {'accuracy': 0.819672131147541,\n",
       "     'precision': 0.823076923076923,\n",
       "     'recall': 0.8168103448275862,\n",
       "     'f1_score': 0.817910447761194},\n",
       "    'model_knn': {'accuracy': 0.7868852459016393,\n",
       "     'precision': 0.795045045045045,\n",
       "     'recall': 0.7823275862068966,\n",
       "     'f1_score': 0.783155592015313},\n",
       "    'model_rf': {'accuracy': 0.8360655737704918,\n",
       "     'precision': 0.8427777777777778,\n",
       "     'recall': 0.8324353448275862,\n",
       "     'f1_score': 0.8338779956427015}}},\n",
       "  'split_0.8': {'trial_0': {'model_log': {'accuracy': 0.823045267489712,\n",
       "     'precision': 0.8233356449375866,\n",
       "     'recall': 0.8186944634313056,\n",
       "     'f1_score': 0.820306454109271},\n",
       "    'model_svm': {'accuracy': 0.757201646090535,\n",
       "     'precision': 0.756336405529954,\n",
       "     'recall': 0.758544087491456,\n",
       "     'f1_score': 0.7563930470834113},\n",
       "    'model_tree': {'accuracy': 0.720164609053498,\n",
       "     'precision': 0.722875816993464,\n",
       "     'recall': 0.7097744360902256,\n",
       "     'f1_score': 0.711118881118881},\n",
       "    'model_perc': {'accuracy': 0.7777777777777778,\n",
       "     'precision': 0.7788696123610734,\n",
       "     'recall': 0.7812713602187287,\n",
       "     'f1_score': 0.7774725274725275},\n",
       "    'model_mlp': {'accuracy': 0.8024691358024691,\n",
       "     'precision': 0.8009259259259259,\n",
       "     'recall': 0.7998974709501026,\n",
       "     'f1_score': 0.8003560180747639},\n",
       "    'model_knn': {'accuracy': 0.7818930041152263,\n",
       "     'precision': 0.7802363936228697,\n",
       "     'recall': 0.7787423103212576,\n",
       "     'f1_score': 0.7793671731793809},\n",
       "    'model_rf': {'accuracy': 0.7901234567901234,\n",
       "     'precision': 0.7937766714082504,\n",
       "     'recall': 0.7823308270676692,\n",
       "     'f1_score': 0.7848624251367068}},\n",
       "   'trial_1': {'model_log': {'accuracy': 0.823045267489712,\n",
       "     'precision': 0.822567287784679,\n",
       "     'recall': 0.8194805194805195,\n",
       "     'f1_score': 0.8206642066420664},\n",
       "    'model_svm': {'accuracy': 0.8353909465020576,\n",
       "     'precision': 0.8488636363636364,\n",
       "     'recall': 0.8252563226247436,\n",
       "     'f1_score': 0.8295454545454546},\n",
       "    'model_tree': {'accuracy': 0.7078189300411523,\n",
       "     'precision': 0.7073613086770981,\n",
       "     'recall': 0.6992822966507177,\n",
       "     'f1_score': 0.7004947487197292},\n",
       "    'model_perc': {'accuracy': 0.8065843621399177,\n",
       "     'precision': 0.8057971014492754,\n",
       "     'recall': 0.8028708133971292,\n",
       "     'f1_score': 0.8039818072599331},\n",
       "    'model_mlp': {'accuracy': 0.831275720164609,\n",
       "     'precision': 0.8388172043010753,\n",
       "     'recall': 0.823069036226931,\n",
       "     'f1_score': 0.8265766157809535},\n",
       "    'model_knn': {'accuracy': 0.7983539094650206,\n",
       "     'precision': 0.8024182076813655,\n",
       "     'recall': 0.7906356801093644,\n",
       "     'f1_score': 0.7932991927784047},\n",
       "    'model_rf': {'accuracy': 0.8024691358024691,\n",
       "     'precision': 0.8075110666857062,\n",
       "     'recall': 0.7943950786056049,\n",
       "     'f1_score': 0.797246558197747}},\n",
       "   'trial_2': {'model_log': {'accuracy': 0.8148148148148148,\n",
       "     'precision': 0.8132616732849514,\n",
       "     'recall': 0.8127477785372522,\n",
       "     'f1_score': 0.8129906110512544},\n",
       "    'model_svm': {'accuracy': 0.8106995884773662,\n",
       "     'precision': 0.8089883800410116,\n",
       "     'recall': 0.8089883800410116,\n",
       "     'f1_score': 0.8089883800410116},\n",
       "    'model_tree': {'accuracy': 0.7078189300411523,\n",
       "     'precision': 0.7073613086770981,\n",
       "     'recall': 0.6992822966507177,\n",
       "     'f1_score': 0.7004947487197292},\n",
       "    'model_perc': {'accuracy': 0.7654320987654321,\n",
       "     'precision': 0.7652418371494378,\n",
       "     'recall': 0.767634996582365,\n",
       "     'f1_score': 0.7648586707410236},\n",
       "    'model_mlp': {'accuracy': 0.8189300411522634,\n",
       "     'precision': 0.8195661243220692,\n",
       "     'recall': 0.814149008885851,\n",
       "     'f1_score': 0.81593444429142},\n",
       "    'model_knn': {'accuracy': 0.7818930041152263,\n",
       "     'precision': 0.7942293373045421,\n",
       "     'recall': 0.7700956937799044,\n",
       "     'f1_score': 0.7730372720063441},\n",
       "    'model_rf': {'accuracy': 0.7901234567901234,\n",
       "     'precision': 0.7937766714082504,\n",
       "     'recall': 0.7823308270676692,\n",
       "     'f1_score': 0.7848624251367068}}}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def query_data(_dataset_name, _model_name, dataset_scores=dataset_scores):\n",
    "    split_02 = []\n",
    "    split_05 = []\n",
    "    split_08 = []\n",
    "    for split_name, split_data in dataset_scores[\"data_adult\"].items():\n",
    "        for trial_name, trial_data in split_data.items():\n",
    "            if split_name==\"split_0.2\":\n",
    "                split_02.append(trial_data[_model_name][\"accuracy\"])\n",
    "            elif split_name==\"split_0.5\":\n",
    "                split_05.append(trial_data[_model_name][\"accuracy\"])\n",
    "            elif split_name==\"split_0.8\":\n",
    "                split_08.append(trial_data[_model_name][\"accuracy\"])\n",
    "\n",
    "    df = pd.DataFrame([split_02, split_05, split_08], columns=[\"Trial 1\", \"Trial 2\", \"Trial 3\"])\n",
    "    df[\"Trial_Avg\"] = df.T.mean()\n",
    "    df.loc[3] = df.mean()\n",
    "    df = df.rename({0:\"Split 0.2\", 1:\"Split 0.5\", 2: \"Split 0.8\", 3: \"Split_Avg\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_table(_split_name, dataset_scores=dataset_scores, models=models):\n",
    "    dataset_adult = []\n",
    "    dataset_heart = []\n",
    "    dataset_mush = []\n",
    "    for dataset_name, dataset_data in dataset_scores.items():\n",
    "        for trial_name, trial_data in dataset_data[_split_name].items():\n",
    "            for model_name, model_data in trial_data.items():\n",
    "                print(dataset_name, trial_name, model_name, model_data)\n",
    "            if dataset_name == \"data_adult\":\n",
    "                pass\n",
    "#                 print(trial_data)\n",
    "#                 dataset_adult.append()\n",
    "#             print(f\"{dataset_name}-{_split_name}-{trial_name}\")\n",
    "\n",
    "    return\n",
    "    df = pd.DataFrame([split_02, split_05, split_08], columns=[\"Trial 1\", \"Trial 2\", \"Trial 3\"])\n",
    "    df[\"Trial_Avg\"] = df.T.mean()\n",
    "    df.loc[3] = df.mean()\n",
    "    df = df.rename({0:\"Split 0.2\", 1:\"Split 0.5\", 2: \"Split 0.8\", 3: \"Split_Avg\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_adult trial_0 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_0 model_svm {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_0 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_0 model_perc {'accuracy': 0.9986692599037773, 'precision': 0.9992717902755994, 'recall': 0.9924065420560748, 'f1_score': 0.9958098499293646}\n",
      "data_adult trial_0 model_mlp {'accuracy': 0.999181083017709, 'precision': 0.999551619773568, 'recall': 0.9953271028037383, 'f1_score': 0.9974282914789022}\n",
      "data_adult trial_0 model_knn {'accuracy': 0.954550107482854, 'precision': 0.8609517384899257, 'recall': 0.8510091974234841, 'f1_score': 0.8558918206877745}\n",
      "data_adult trial_0 model_rf {'accuracy': 0.9353055583990173, 'precision': 0.9668936616029336, 'recall': 0.6308411214953271, 'f1_score': 0.690287459417376}\n",
      "data_adult trial_1 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_1 model_svm {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_1 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_1 model_perc {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_1 model_mlp {'accuracy': 0.9995905415088545, 'precision': 0.9997757093192778, 'recall': 0.9976635514018692, 'f1_score': 0.9987168693134876}\n",
      "data_adult trial_1 model_knn {'accuracy': 0.9586446923943085, 'precision': 0.9015480348383287, 'recall': 0.8226282805436981, 'f1_score': 0.8567566194254985}\n",
      "data_adult trial_1 model_rf {'accuracy': 0.9940628518783908, 'precision': 0.9967673614981607, 'recall': 0.9661214953271028, 'f1_score': 0.9808451861073255}\n",
      "data_adult trial_2 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_2 model_svm {'accuracy': 0.9993858122632818, 'precision': 0.9991327821890034, 'recall': 0.9970233414177129, 'f1_score': 0.9980753039702315}\n",
      "data_adult trial_2 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_adult trial_2 model_perc {'accuracy': 0.9985668952809909, 'precision': 0.995518530110906, 'recall': 0.995518530110906, 'f1_score': 0.995518530110906}\n",
      "data_adult trial_2 model_mlp {'accuracy': 0.9993858122632818, 'precision': 0.9965197215777262, 'recall': 0.9996634129922586, 'f1_score': 0.9980854333008}\n",
      "data_adult trial_2 model_knn {'accuracy': 0.9578257754120176, 'precision': 0.9190843957720388, 'recall': 0.7984188536957988, 'f1_score': 0.8463472997199394}\n",
      "data_adult trial_2 model_rf {'accuracy': 0.9965196028252636, 'precision': 0.9980999217614843, 'recall': 0.9801401869158879, 'f1_score': 0.9889170438331774}\n",
      "data_mush trial_0 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_0 model_svm {'accuracy': 0.9046153846153846, 'precision': 0.9211597151576806, 'recall': 0.9027603513174405, 'f1_score': 0.9033491185247746}\n",
      "data_mush trial_0 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_0 model_perc {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_0 model_mlp {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_0 model_knn {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_0 model_rf {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_svm {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_perc {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_mlp {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_knn {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_1 model_rf {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_2 model_log {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_2 model_svm {'accuracy': 0.9993846153846154, 'precision': 0.9993968636911943, 'recall': 0.9993726474278545, 'f1_score': 0.9993843766538958}\n",
      "data_mush trial_2 model_tree {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_2 model_perc {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_mush trial_2 model_mlp {'accuracy': 0.9993846153846154, 'precision': 0.9993968636911943, 'recall': 0.9993726474278545, 'f1_score': 0.9993843766538958}\n",
      "data_mush trial_2 model_knn {'accuracy': 0.9993846153846154, 'precision': 0.9993968636911943, 'recall': 0.9993726474278545, 'f1_score': 0.9993843766538958}\n",
      "data_mush trial_2 model_rf {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "data_heart trial_0 model_log {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_0 model_svm {'accuracy': 0.7377049180327869, 'precision': 0.741111111111111, 'recall': 0.7338362068965517, 'f1_score': 0.7342047930283224}\n",
      "data_heart trial_0 model_tree {'accuracy': 0.8032786885245902, 'precision': 0.8163615560640732, 'recall': 0.7979525862068966, 'f1_score': 0.798901098901099}\n",
      "data_heart trial_0 model_perc {'accuracy': 0.7540983606557377, 'precision': 0.7786585365853658, 'recall': 0.7462284482758621, 'f1_score': 0.7441990494828068}\n",
      "data_heart trial_0 model_mlp {'accuracy': 0.8032786885245902, 'precision': 0.8088888888888889, 'recall': 0.7995689655172413, 'f1_score': 0.8006535947712419}\n",
      "data_heart trial_0 model_knn {'accuracy': 0.7704918032786885, 'precision': 0.775, 'recall': 0.7667025862068966, 'f1_score': 0.7674291938997821}\n",
      "data_heart trial_0 model_rf {'accuracy': 0.8360655737704918, 'precision': 0.8376906318082789, 'recall': 0.834051724137931, 'f1_score': 0.83495670995671}\n",
      "data_heart trial_1 model_log {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_1 model_svm {'accuracy': 0.8032786885245902, 'precision': 0.8088888888888889, 'recall': 0.7995689655172413, 'f1_score': 0.8006535947712419}\n",
      "data_heart trial_1 model_tree {'accuracy': 0.8360655737704918, 'precision': 0.8427777777777778, 'recall': 0.8324353448275862, 'f1_score': 0.8338779956427015}\n",
      "data_heart trial_1 model_perc {'accuracy': 0.7540983606557377, 'precision': 0.79328165374677, 'recall': 0.7446120689655172, 'f1_score': 0.7404255319148937}\n",
      "data_heart trial_1 model_mlp {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_1 model_knn {'accuracy': 0.7704918032786885, 'precision': 0.7814645308924485, 'recall': 0.7650862068965517, 'f1_score': 0.7653846153846153}\n",
      "data_heart trial_1 model_rf {'accuracy': 0.8360655737704918, 'precision': 0.8376906318082789, 'recall': 0.834051724137931, 'f1_score': 0.83495670995671}\n",
      "data_heart trial_2 model_log {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_2 model_svm {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_2 model_tree {'accuracy': 0.8032786885245902, 'precision': 0.8088888888888889, 'recall': 0.7995689655172413, 'f1_score': 0.8006535947712419}\n",
      "data_heart trial_2 model_perc {'accuracy': 0.8360655737704918, 'precision': 0.8376906318082789, 'recall': 0.834051724137931, 'f1_score': 0.83495670995671}\n",
      "data_heart trial_2 model_mlp {'accuracy': 0.819672131147541, 'precision': 0.823076923076923, 'recall': 0.8168103448275862, 'f1_score': 0.817910447761194}\n",
      "data_heart trial_2 model_knn {'accuracy': 0.7868852459016393, 'precision': 0.795045045045045, 'recall': 0.7823275862068966, 'f1_score': 0.783155592015313}\n",
      "data_heart trial_2 model_rf {'accuracy': 0.8360655737704918, 'precision': 0.8427777777777778, 'recall': 0.8324353448275862, 'f1_score': 0.8338779956427015}\n"
     ]
    }
   ],
   "source": [
    "data_table(\"split_0.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happiness Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# happy_df = pd.concat({\"Log Regression\": query_data(\"data_happy\", \"model_log\"),\n",
    "#                       \"SVM\" : query_data(\"data_happy\", \"model_svm\"),\n",
    "#                       \"Decision Tree\" : query_data(\"data_happy\", \"model_tree\"),\n",
    "#                       \"Perceptron\" : query_data(\"data_happy\", \"model_perc\"),\n",
    "#                       \"MLP\" : query_data(\"data_happy\", \"model_mlp\"),\n",
    "#                      \"KNN\" : query_data(\"data_happy\", \"model_knn\"),\n",
    "#                      \"Random Forest\" : query_data(\"data_happy\", \"model_rf\")})\n",
    "# happy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = pd.concat({\"Log Regression\": query_data(\"data_adult\", \"model_log\"),\n",
    "                      \"SVM\" : query_data(\"data_adult\", \"model_svm\"),\n",
    "                      \"Decision Tree\" : query_data(\"data_adult\", \"model_tree\"),\n",
    "                      \"Perceptron\" : query_data(\"data_adult\", \"model_perc\"),\n",
    "                      \"MLP\" : query_data(\"data_adult\", \"model_mlp\"),\n",
    "                     \"KNN\" : query_data(\"data_adult\", \"model_knn\"),\n",
    "                     \"Random Forest\" : query_data(\"data_adult\", \"model_rf\")})\n",
    "adult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mush_df = pd.concat({\"Log Regression\": query_data(\"data_mush\", \"model_log\"),\n",
    "                              \"SVM\" : query_data(\"data_mush\", \"model_svm\"),\n",
    "                    \"Decision Tree\" : query_data(\"data_mush\", \"model_tree\"),\n",
    "                    \"Perceptron\" : query_data(\"data_mush\", \"model_perc\"),\n",
    "                    \"MLP\" : query_data(\"data_mush\", \"model_mlp\"),\n",
    "                    \"KNN\" : query_data(\"data_mush\", \"model_knn\"),\n",
    "                    \"Random Forest\" : query_data(\"data_mush\", \"model_rf\")})\n",
    "mush_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.concat({\"Log Regression\": query_data(\"data_heart\", \"model_log\"),\n",
    "                              \"SVM\" : query_data(\"data_heart\", \"model_svm\"),\n",
    "                     \"Decision Tree\" : query_data(\"data_heart\", \"model_tree\"),\n",
    "                     \"Perceptron\" : query_data(\"data_heart\", \"model_perc\"),\n",
    "                     \"MLP\" : query_data(\"data_heart\", \"model_mlp\"),\n",
    "                     \"KNN\" : query_data(\"data_heart\", \"model_knn\"),\n",
    "                     \"Random Forest\" : query_data(\"data_heart\", \"model_rf\")})\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.concat({\"Adult\" : adult_df, \"Mush\" : mush_df, \"Heart\" : heart_df})\n",
    "main_df.to_csv(\"data/main_df.csv\")\n",
    "main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single person project and no team work.\n",
    "\n",
    "Report format:\n",
    "\n",
    "Write a report with >1,000 words (excluding references) including main sections: a) abstract, b) introduction, c) method, d) experiment, e) conclusion, and f) references. You can follow the paper format as e.g leading machine learning journals such as Journal of Machine Learning Research (http://www.jmlr.org/) or IEEE Trans. on Pattern Analysis and Machine Intelligence (http://www.computer.org/web/tpami), or leading conferences like NeurIPS (https://papers.nips.cc/) and ICML (https://icml.cc/). There is no page limit for your report.\n",
    "\n",
    "Bonus points: \n",
    "\n",
    "If you feel that your work deserves bonus points due to reasons such as: a) novel ideas and applications, b) large efforts in your own data collection/preparation, c) state-of-the-art classification results, or d) new algorithms, please create a \"Bonus Points\" section to specifically describe why you deserve bonus points.\n",
    "\n",
    "In this project you will choose any three classifiers out of those tested in\n",
    "\n",
    "\n",
    "We have been discussing the classification problem in the form of two-class classifiers throughout the class. Some classifiers like decision tree, KNN, random forests stay agnostic w.r.t the number of classes but others like SVM and Boosting where explicit objective functions are involved don't.\n",
    "\n",
    "\n",
    "\n",
    "The basic requirement for the final project is based on the two-class classification problem. If you have additional bandwidth, you can experiment on the multi-class classification setting. When preparing the dataset to train your classifier (two-class), please try to merge the labels into two groups, positives and negatives, if your dataset happens to consist multi-class labels.\n",
    "\n",
    "\n",
    "\n",
    "Train your classifiers using the setting (not all metrics are needed) described in the empirical study by Caruana and Niculescu-Mizil. You are supposed to reproduce consistent results as in the paper. However, do expect some small variations. When evaluating the algorithms, you don’t need to use all the metrics that were reported in the paper. Using one metric, e.g. the classification accuracy, is sufficient. Please report the cross-validated classification results with the corresponding learned hyper-parameters.\n",
    "\n",
    "Note that since you are choosing your own libraries for the classifiers, there are implementation details that will affect the classification results. Even the same SVM but with different implementations, you won't be able to see identical results when trained on the same dataset. Therefore, don't expect the identical results as those in the paper, as you are probably using a subset and not all the features. If you see a bit difference in ranking, it should ok but the overall trend should be consistent, e.g. random forest should do well, more training data leads to better results, knn is not necessarily very bad etc.\n",
    "\n",
    "If you compute accuracy and follow the basic requirement picking 3 classifiers and 3 datasets. You are looking at 3 trials X 3 classifiers X 3 datasets X 3 partitions (20/80, 50/50, 80/20). Each time you always report the best accuracy under the chosen hyper-parameter. Since for the accuracy is averaged among three 3 trials to rank order the classifiers, you will report 3 classifiers X 3 datasets X 3 partitions  (20/80, 50/50, 80/20)  X 3. accuracies (train, validation, test). When trying to debug, always try to see the training accuracy to see if you are able to at least push the training accuracy high (to overfit the data) as a sanity check making sure your implementation is correct. The heatmaps for your hyper-parameters are the details that do not need to be too carefully compared with. The searching for the hyper-parameters is internal and the final conclusion about the classifiers is based on the best hyper-parameter you have obtained for each time.\n",
    "\n",
    "Since the exact data setting might have changed, the specific parameters and hyper-parameters reported in Caruana and Niculescu-Mizil paper serve as a guideline but you don't need to try all of them. You can try a few standard ones, as long as your classification results are reasonable. If you pick the multi-layer perceptron as one of your classifiers, note that you may need to increase the number of layers to e.g. 3 and create more neurons in each layer to attain good results, for some datasets.\n",
    "\n",
    "You can alternatively or additionally adopt the datasets and classifiers reported in a follow-up paper, Caruana et al. ICML 2008.\n",
    " \n",
    "You are encouraged to use Python, but using other programming languages and platforms is ok. The candidate classifiers include:\n",
    "1. Boosting family classifiers\n",
    "http://www.mathworks.com/matlabcentral/fileexchange/21317-adaboost\n",
    "or\n",
    "https://github.com/dmlc/xgboost\n",
    "2. Support vector machines\n",
    "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
    "3. Random Forests\n",
    "http://www.stat.berkeley.edu/~breiman/RandomForests/\n",
    "4. Decision Tree\n",
    "http://www.rulequest.com/Personal/ (please see also see a sample matlab code in the attachment)\n",
    "5. K-nearest neighbors\n",
    "http://www.mathworks.com/matlabcentral/fileexchange/19345-efficient-k-nearest-neighbor-searchusing-jit\n",
    "6. Neural Nets\n",
    "http://www.cs.colostate.edu/~anderson/code/\n",
    "http://www.mathworks.com/products/neural-network/code-examples.html\n",
    "7. Logistic regression classifier\n",
    "8. Bagging family\n",
    "\n",
    "The links above are for your reference. You can implement your own classifier or download other\n",
    "versions you like online (But you need to make sure the code online is reliable). You are supposed to\n",
    "write a formal report describing about the experiments you run and the corresponding results (plus\n",
    "code).\n",
    "\n",
    "\n",
    "Grading\n",
    "Note that if you do well by satisfying the minimum requirement e.g. 3 classifiers on 3 datasets with cross-validation, you will receive a decent score but not the full 100 points. We are looking for something a bit more and please see the guideline below.\n",
    "\n",
    "When reporting the experimental results, there are two main sets of comparisons we are looking for:\n",
    "a. For each dataset on each paritition, show the comparison for different algorithms, and hopefully be consistent with the findings in the paper with Random Forests being the best etc.\n",
    "b. For each classifier on each partition, show the comparison on different partitions and you are supposed to show the increase of test accuracy (decrease of test error) with more training data and less test data.\n",
    "\n",
    "Note that the performance and function calls vary due to the particular ML libraries you are using. For example, the same SVM classifier provided in different toolboxes might result in different errors even trained on the same dataset. But the overall differences should be reasonable and interpretable. You may obtain a ranking that is somewhat different from that in the paper, due to differences in detailed implementation of the classifiers, different training sizes, features ect. But the overall trend should be explainable. For example, random forest usually has a pretty good performance; knn might not be as bad as you had thought, kernel-based SVM is sometimes sensitive to the hyper-parameters; using more data in training will lead to improvement, especially on difficult cases.\n",
    "\n",
    "The merit and grading of your project can be judged from aspects described below that are common\n",
    "when reviewing a paper:\n",
    "1. How challenging and large are the datasets you are studying? (10 points)\n",
    "2. Any aspects that are new in terms of algorithm development, uniqueness of the data, or new\n",
    "applications? (10 points)\n",
    "3. Is your experimental design comprehensive? Have you done thoroughly experiments in tuning\n",
    "hyper-parameters and performing cross validation (you should also try different data partitions, e.g 20% training and 80% testing, 50% training and 50% testing, and 80% training and 20% testing for multiple rounds, e.g. 3 times each for the above three partitions and compute average scores to remove potentials of having accidental results); try to report both the training and testing errors after cross-validation; it is encouraged to also report the training and validation errors during cross-validation using classification error/accuracy curves w.r.t. the hyper-parameters. (50 points)\n",
    "4. Is your report written in a professional way with sections including abstract, introduction, data\n",
    "and problem description, method description, experiments, conclusion, and references? (30\n",
    "points)\n",
    "5. Bonus points will be assigned to projects in which new ideas have been developed and implemented, or thorough experiments where extensive empirical studies have been carried out (e.g. evaluated on >=5 classifiers and >=4 datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "https://stackoverflow.com/questions/47793569/choosing-top-k-models-using-gridsearchcv-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
